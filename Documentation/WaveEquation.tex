\documentclass{article}
\usepackage{amsmath}
\usepackage{fullpage}
\begin{document}
\flushleft
{\large Discretizing and Numerically Solving the Wave Equation}

The Physics behind WaveEquationInefficient.py and WaveEquationOptimized.py

\smallskip
Varadarajan Srinivasan
\bigskip


For a function $f(x)$ whose discretization is represented as a sequence $f_n$, we define its numerical derivative with respect to $x$, nD$_x(f_n)$, as the average of the forward difference and backward difference.
\begin{equation} \label{1st deriv 1d}
\mbox{nD}_x(f_n)=\frac{1}{2}\left(\frac{f_{n}-f_{n-1}}{\Delta x}+\frac{f_{n+1}-f_n}{\Delta x}\right)=\frac{f_{n+1}-f_{n-1}}{2\Delta x}
\end{equation}
For differentiable functions, this approximates the true derivative of the function to an arbitrarily high accuracy as the step size $\Delta x \rightarrow 0$. As explained in DiscretizedLaplaceEquation.pdf, this logically produces the one-dimensional numerical second derivative $\mbox{nD}_x^2(f_n)$ as well as the numerical Laplacian nD$_{x,y}^2(f_{m,n})$ for our evenly spaced grid ($\Delta x = \Delta y \equiv \Delta$).
\begin{equation} \label{2nd deriv 1d}
\mbox{nD}_x^2(f_n)=\mbox{nD}(\mbox{nD}(f_n))=\frac{f_{n+1}-2f_{n}+f_{n-1}}{\Delta^2}
\end{equation}
\begin{equation} \label{Laplacian}
\mbox{nD}_{x,y}^2(f_{m,n})=\frac{f_{m,n+1}+f_{m,n-1}+f_{m+1,n}+f_{m-1,n}-4f_{m,n}}{\Delta^2}
\end{equation}

\bigskip

Using these discretizations, the Wave Equation for displacement $f$,
\begin{equation} \label{wave equation}
\frac{\partial^2f}{\partial t^2}=c^2\nabla^2f,
\end{equation}
can be numerically approximated as
\begin{equation} \label{wave discr}
\mbox{nD}_t^2(f_{m,n,t})=c^2\mbox{nD}_{x,y}^2(f_{m,n,t}).
\end{equation}
Substituting Eq. \ref{2nd deriv 1d} and Eq. \ref{Laplacian} into Eq. \ref{wave discr} gives us
\begin{equation*}
\frac{f_{m,n,t+1}-2f_{m,n,t}+f_{m,n,t-1}}{(\Delta t)^2}=\frac{c^2}{\Delta^2}(f_{m,n+1,t}+f_{m,n-1,t}+f_{m+1,n,t}+f_{m-1,n,t}-4f_{m,n,t})
\end{equation*}
Rearranging and subtracting one time step from every term gives us the desired iterative formula that solves the wave equation for given boundary conditions
\begin{equation} \label{wave eqn solution}
\boxed{f_{m,n,t}=K(f_{m,n+1,t-1}+f_{m,n-1,t-1}+f_{m+1,n,t-1}+f_{m-1,n,t-1}-4f_{m,n,t-1})+2f_{m,n,t-1}-f_{m,n,t-2}}
\end{equation}
where
\begin{equation} \label{K}
K=c^2\frac{(\Delta t)^2}{\Delta^2}
\end{equation}
is a constant which can be thought of as the square of the ratio between the speed of the wave through the plane and the information propagation speed of the numerical method. In each time-step $\Delta t$, Eq. \ref{wave eqn solution} transmits information from a distance of exactly 1 grid point in every direction. This means that the information propagation speed is $c_{i}=\Delta / \Delta t$.

For the numerical method to successfully approximate the wave equation, numerical stability is necessary. That is, the speed of the information propagation throughout our discretization must be no slower than the wave speed $c\leq c_i$. Otherwise, our results will be nonsensical. Noting all these parameters are necessarily positive, we see that
\begin{equation} \label{K<=1}
\frac{c}{c_i}\leq 1 \implies \frac{c\Delta t}{\Delta}\leq 1 \implies K\leq 1
\end{equation}
is a necessary condition for numerical stability in our method. We can get a more specific necessary condition by invoking the time-marching (explicit) case of the Courant--Friedrichs--Lewy condition that
\begin{equation}
\Delta t\left(\frac{c_x}{\Delta x}+\frac{c_y}{\Delta y}\right)\leq C_{max}=1
\end{equation}
which, for our method, becomes
\begin{equation} \label{CFL our case}
\frac{\Delta t}{\Delta}(c_x+c_y)\leq 1
\end{equation}
This is of course consistent with Ineq. \ref{K<=1} by the Triangle Inequality. Note that even our more restricted condition Ineq. \ref{CFL our case} is not necessarily a sufficient one. However, the results of the method become obviously nonsensical when the condition to ensure stability is not met and so we need not derive it. Running several tests makes it clear that $K\leq 0.5$ is comfortably sufficient for our purposes with $0.1\leq K\leq 0.4$ being a good compromise. Low values of K produce more accurate results, but are algorithmically slower. Essentially, lowering K increases our time-resolution.
\end{document}